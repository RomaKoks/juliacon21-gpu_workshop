{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71bc650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_PKG_NAME = \"AMDGPU\"; include(\"common_definitions.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026100d8",
   "metadata": {},
   "source": [
    "Not everything is peachy in kernel land; some things that you can easily do on the Julia host, you can't so easily do when executing on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb71f9",
   "metadata": {},
   "source": [
    "For example, Julia on the host has access to a fast RNG that can be called from multiple threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00552c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×8 Matrix{Float64}:\n",
       " 0.992543  0.300562   0.247534  0.248511  …  0.517549  0.705719  0.253429\n",
       " 0.396288  0.0460697  0.595105  0.390061     0.291689  0.865059  0.453826\n",
       " 0.928109  0.959506   0.139073  0.786756     0.12094   0.682744  0.173941\n",
       " 0.831055  0.701795   0.318094  0.452323     0.490569  0.221822  0.416229"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = rand(4, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82273ace",
   "metadata": {},
   "source": [
    "When using a GPU computing library, it's pretty easy to use the vendor's RNG library to get random numbers quite easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8343cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×8 ROCMatrix{Float32}:\n",
       " 0.257441  0.553337  0.519232    0.486345  …  0.975905  0.034095  0.398251\n",
       " 0.973872  0.310398  0.273645    0.457593     0.440681  0.481178  0.373012\n",
       " 0.10861   0.895063  0.370645    0.084692     0.198199  0.608729  0.581116\n",
       " 0.5859    0.270586  0.00915819  0.486293     0.060693  0.756005  0.29821"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = GPUMOD.rand(4, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e97ad",
   "metadata": {},
   "source": [
    "However, note well that this allocation is being driven by the host; allocating random numbers directly from a GPU kernel is much trickier, and only became convenient recently (and only for CUDA users)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d11ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":'(\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "if GPU_PKG_NAME == \"CUDA\"\n",
    "    @kernel function kernel(X)\n",
    "        idx = @index(Global, Linear)\n",
    "        X[idx] += GPUMOD.rand()\n",
    "    end\n",
    "    k = kernel(GpuBackend)\n",
    "    function bench()\n",
    "        kernels = [k(X; ndrange=32) for i in 1:100]\n",
    "        wait.(kernels);\n",
    "    end\n",
    "    @benchmark bench()\n",
    "else\n",
    "    println(\":'(\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33549fa",
   "metadata": {},
   "source": [
    "For the AMD and Intel users out there, or for CUDA users who can't use this functionality, we can fall back to generating random numbers on the CPU, and explicitly passing them into the GPU kernel. We'll make sure to allocate one random number for each thread that'll be launched; if you launch multiple blocks, or with multiple dimensions, make sure to account for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e063b6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 2087 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.349 ms\u001b[22m\u001b[39m … \u001b[35m  3.400 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.360 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.387 ms\u001b[22m\u001b[39m ± \u001b[32m130.514 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[34m \u001b[39m\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m█\u001b[34m▆\u001b[39m\u001b[39m▆\u001b[32m▄\u001b[39m\u001b[39m▅\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▂\n",
       "  1.35 ms\u001b[90m         Histogram: frequency by time\u001b[39m        2.64 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m11.33 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m246\u001b[39m."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function kernel(X, R)\n",
    "    idx = @index(Global, Linear)\n",
    "    X[idx] += R[idx]\n",
    "end\n",
    "k = kernel(GpuBackend)\n",
    "function bench()\n",
    "    kernels = [k(X, GPUMOD.rand(32); ndrange=32)]\n",
    "    wait.(kernels);\n",
    "end\n",
    "@benchmark bench()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e2d9d2",
   "metadata": {},
   "source": [
    "This will work OK, but it won't give you very good performance if you have to allocate random numbers on the CPU before every kernel launch. Instead, we could pre-allocate a large buffer of random numbers, and use an integer index to determine which numbers to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8129fd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 585 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m7.339 ms\u001b[22m\u001b[39m … \u001b[35m53.477 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 13.03%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m7.450 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m8.548 ms\u001b[22m\u001b[39m ± \u001b[32m 6.011 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m1.97% ±  2.32%\n",
       "\n",
       "  \u001b[34m█\u001b[39m\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[34m█\u001b[39m\u001b[39m▄\u001b[32m▁\u001b[39m\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▅\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▆\u001b[39m \u001b[39m▆\n",
       "  7.34 ms\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m     45.7 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m1.08 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m22711\u001b[39m."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kernel function kernel(X, R, ridx)\n",
    "    idx = @index(Global, Linear)\n",
    "    X[idx] += R[ridx, idx]\n",
    "end\n",
    "k = kernel(GpuBackend)\n",
    "function bench()\n",
    "    R = GPUMOD.rand(100, 32)\n",
    "    kernels = [k(X, R, i; ndrange=32) for i in 1:100]\n",
    "    wait.(kernels);\n",
    "end\n",
    "@benchmark bench()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20674ec0",
   "metadata": {},
   "source": [
    "Clearly, this still leaves something to be desired; what happens when we run out of random numbers? We could only launch as many kernels at a time as we have unique random numbers, refill the random array, and continue launching kernels. That works, although you'll have to wait for all of the currently-executing kernels to finish (to be safe)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf42ae6",
   "metadata": {},
   "source": [
    "Is there anything further we can do? If you're on an AMD GPU, you can do something a bit fancier: you could use the hostcall mechanism to have the GPU request random numbers from the CPU as-needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a63a53d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 5 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.112 s\u001b[22m\u001b[39m … \u001b[35m 1.129 s\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.126 s             \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.124 s\u001b[22m\u001b[39m ± \u001b[32m6.626 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m█\u001b[34m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[39m \u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[32m▁\u001b[39m\u001b[39m█\u001b[34m▁\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m \u001b[39m▁\n",
       "  1.11 s\u001b[90m        Histogram: frequency by time\u001b[39m        1.13 s \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m1.31 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m29328\u001b[39m."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if GPU_PKG_NAME == \"AMDGPU\"\n",
    "    @kernel function kernel(X, hc)\n",
    "        idx = @index(Global, Linear)\n",
    "        R = hostcall!(hc)\n",
    "        X[idx] += R[idx]\n",
    "    end\n",
    "    k = kernel(GpuBackend)\n",
    "\n",
    "    hc = HostCall(ROCDeviceArray{Float32,1,1}, Tuple{}; continuous=true) do\n",
    "        R = AMDGPU.rand(32)\n",
    "        return rocconvert(R) # make it device-compatible\n",
    "    end\n",
    "\n",
    "    function bench()\n",
    "        kernels = [k(X, hc; ndrange=32) for i in 1:100]\n",
    "        wait.(kernels);\n",
    "    end\n",
    "    @benchmark bench()\n",
    "else\n",
    "    println(\":(\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf71b06",
   "metadata": {},
   "source": [
    "This approach written as-is will perform poorly, since the hostcall task is currently single-threaded, and is spending most of its time communicating with the GPU; real applications will generally make far larger kernels invocations, which should make this approach feasible in certain situations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cea2a14",
   "metadata": {},
   "source": [
    "Regardless of which kind of GPU you use, situations like these inevitably come up, and aren't just related to random numbers. You should always aim to structure your program to let the CPU do as little work as possible, and let the GPU do the heavy lifting. This might be accomplished by pre-allocating large buffers all at once, using task parallelism to minimize the latency of CPU-bound operations, and even trying your hand at re-implementing functionality (like RNGs) as GPU kernels.\n",
    "\n",
    "(Of course, it's probably best if you don't implement an RNG by hand for anything security-related!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
