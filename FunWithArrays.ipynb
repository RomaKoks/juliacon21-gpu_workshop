{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68129ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "// Immediately-invoked-function-expression to avoid global variables.\n",
       "(function() {\n",
       "    var warning_div = document.getElementById(\"webio-warning-13630523490842699920\");\n",
       "    var hide = function () {\n",
       "        var script = document.getElementById(\"webio-setup-3799507991530942102\");\n",
       "        var parent = script && script.parentElement;\n",
       "        var grandparent = parent && parent.parentElement;\n",
       "        if (grandparent) {\n",
       "            grandparent.style.display = \"none\";\n",
       "        }\n",
       "        warning_div.style.display = \"none\";\n",
       "    };\n",
       "    if (typeof Jupyter !== \"undefined\") {\n",
       "        console.log(\"WebIO detected Jupyter notebook environment.\");\n",
       "        // Jupyter notebook.\n",
       "        var extensions = (\n",
       "            Jupyter\n",
       "            && Jupyter.notebook.config.data\n",
       "            && Jupyter.notebook.config.data.load_extensions\n",
       "        );\n",
       "        if (extensions && extensions[\"webio-jupyter-notebook\"]) {\n",
       "            // Extension already loaded.\n",
       "            console.log(\"Jupyter WebIO nbextension detected; not loading ad-hoc.\");\n",
       "            hide();\n",
       "            return;\n",
       "        }\n",
       "    } else if (window.location.pathname.includes(\"/lab\")) {\n",
       "        // Guessing JupyterLa\n",
       "        console.log(\"Jupyter Lab detected; make sure the @webio/jupyter-lab-provider labextension is installed.\");\n",
       "        hide();\n",
       "        return;\n",
       "    }\n",
       "})();\n",
       "\n",
       "</script>\n",
       "<p\n",
       "    id=\"webio-warning-13630523490842699920\"\n",
       "    class=\"output_text output_stderr\"\n",
       "    style=\"padding: 1em; font-weight: bold;\"\n",
       ">\n",
       "    Unable to load WebIO. Please make sure WebIO works for your Jupyter client.\n",
       "    For troubleshooting, please see <a href=\"https://juliagizmos.github.io/WebIO.jl/latest/providers/ijulia/\">\n",
       "    the WebIO/IJulia documentation</a>.\n",
       "    <!-- TODO: link to installation docs. -->\n",
       "</p>\n"
      ],
      "text/plain": [
       "HTML{String}(\"<script>\\n// Immediately-invoked-function-expression to avoid global variables.\\n(function() {\\n    var warning_div = document.getElementById(\\\"webio-warning-13630523490842699920\\\");\\n    var hide = function () {\\n        var script = document.getElementById(\\\"webio-setup-3799507991530942102\\\");\\n        var parent = script && script.parentElement;\\n        var grandparent = parent && parent.parentElement;\\n        if (grandparent) {\\n            grandparent.style.display = \\\"none\\\";\\n        }\\n        warning_div.style.display = \\\"none\\\";\\n    };\\n    if (typeof Jupyter !== \\\"undefined\\\") {\\n        console.log(\\\"WebIO detected Jupyter notebook environment.\\\");\\n        // Jupyter notebook.\\n        var extensions = (\\n            Jupyter\\n            && Jupyter.notebook.config.data\\n            && Jupyter.notebook.config.data.load_extensions\\n        );\\n        if (extensions && extensions[\\\"webio-jupyter-notebook\\\"]) {\\n            // Extension already loaded.\\n            console.log(\\\"Jupyter WebIO nbextension detected; not loading ad-hoc.\\\");\\n            hide();\\n            return;\\n        }\\n    } else if (window.location.pathname.includes(\\\"/lab\\\")) {\\n        // Guessing JupyterLa\\n        console.log(\\\"Jupyter Lab detected; make sure the @webio/jupyter-lab-provider labextension is installed.\\\");\\n        hide();\\n        return;\\n    }\\n})();\\n\\n</script>\\n<p\\n    id=\\\"webio-warning-13630523490842699920\\\"\\n    class=\\\"output_text output_stderr\\\"\\n    style=\\\"padding: 1em; font-weight: bold;\\\"\\n>\\n    Unable to load WebIO. Please make sure WebIO works for your Jupyter client.\\n    For troubleshooting, please see <a href=\\\"https://juliagizmos.github.io/WebIO.jl/latest/providers/ijulia/\\\">\\n    the WebIO/IJulia documentation</a>.\\n    <!-- TODO: link to installation docs. -->\\n</p>\\n\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPU_PKG_NAME = \"AMDGPU\"; include(\"common_definitions.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a975e5c1",
   "metadata": {},
   "source": [
    "Arrays are fun! Let's see what sorts of things we can do with Julia's array interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b443a1d9",
   "metadata": {},
   "source": [
    "Because Machine Learning is hot right now, let's implement some of the basics from scratch. Let's give Flux's Dense layer a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e732857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32-element ROCVector{Float32}:\n",
       " 2.486434\n",
       " 2.1763203\n",
       " 3.0257607\n",
       " 1.2786984\n",
       " 2.6666918\n",
       " 1.9567823\n",
       " 2.9717352\n",
       " 3.1911674\n",
       " 2.710516\n",
       " 3.4692364\n",
       " 2.6519804\n",
       " 2.2051744\n",
       " 2.735538\n",
       " ⋮\n",
       " 1.9065772\n",
       " 2.959194\n",
       " 1.9990909\n",
       " 2.122009\n",
       " 1.884681\n",
       " 2.1215396\n",
       " 1.55394\n",
       " 2.6163301\n",
       " 2.0110452\n",
       " 3.3095946\n",
       " 2.190668\n",
       " 2.3430967"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct Dense\n",
    "    W::GpuArray{Float32,2}\n",
    "    B::GpuArray{Float32,1}\n",
    "end\n",
    "(d::Dense)(X) = d.W * X .+ d.B\n",
    "\n",
    "X = GPUMOD.rand(8) # our input\n",
    "D = Dense(GPUMOD.rand(32, 8), GPUMOD.rand(32)) # our dense layer\n",
    "Y = D(X) # our result, or \"prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d110e",
   "metadata": {},
   "source": [
    "That's surprisingly easy! Although, that's more a testament to how simple the Dense layer is. Of course, the *real* Dense layer also has an extra operation stored within it, the \"activation function\", that'll be applied to the result before it's returned. Let's add that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40725d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32-element ROCVector{Float32}:\n",
       "  0.7117389\n",
       "  0.65917706\n",
       "  0.9962529\n",
       "  0.9598583\n",
       "  0.14423871\n",
       "  0.79629743\n",
       "  0.26667917\n",
       "  0.33245322\n",
       "  0.99117374\n",
       "  0.3005133\n",
       "  0.62377775\n",
       "  0.2911119\n",
       "  0.9891397\n",
       "  ⋮\n",
       "  0.41433883\n",
       "  0.9339969\n",
       " -0.18869163\n",
       "  0.7243287\n",
       "  0.6254028\n",
       "  0.68218803\n",
       "  0.80426913\n",
       "  0.18213595\n",
       "  0.6043187\n",
       "  0.9808556\n",
       "  0.00019446213\n",
       "  0.9997918"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct DenseExtra\n",
    "    W::GpuArray{Float32,2}\n",
    "    B::GpuArray{Float32,1}\n",
    "    op::Function\n",
    "end\n",
    "(d::DenseExtra)(X) = d.op.(d.W * X .+ d.B)\n",
    "\n",
    "# a very strange activation function\n",
    "D = DenseExtra(GPUMOD.rand(32, 8), GPUMOD.rand(32), Base.sin)\n",
    "\n",
    "Y = D(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00053a56",
   "metadata": {},
   "source": [
    "It's pretty simple to apply operations to GPU arrays; just use broadcasting! The GPUArrays package will take care of compiling your operation down into a GPU kernel and executing it for you, so you get great performance. Of course, we could have just hacked in explicit support for `Base.sin` into GPUArrays for this workshop. Let's try to disprove that possibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0710183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32-element ROCVector{Float32}:\n",
       " 1.7694025\n",
       " 1.4593736\n",
       " 1.5504706\n",
       " 2.1202867\n",
       " 1.7502114\n",
       " 2.7722752\n",
       " 2.5464807\n",
       " 2.090945\n",
       " 1.7716358\n",
       " 2.8755188\n",
       " 2.0656824\n",
       " 1.919281\n",
       " 1.9699565\n",
       " ⋮\n",
       " 2.0603788\n",
       " 3.0326064\n",
       " 1.3484907\n",
       " 2.19077\n",
       " 2.591572\n",
       " 3.4285855\n",
       " 2.8133383\n",
       " 1.8792555\n",
       " 2.0648713\n",
       " 1.6753672\n",
       " 3.3227973\n",
       " 2.1942797"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(x) = ifelse(x > 0, x, zero(x))\n",
    "\n",
    "# a more familiar activation function, the famous Rectified Linear Unit\n",
    "D = DenseExtra(GPUMOD.rand(32, 8), GPUMOD.rand(32), relu)\n",
    "\n",
    "Y = D(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e49df",
   "metadata": {},
   "source": [
    "Good luck doing *that* in Python! Julia and the GPU packages cooperate to compile custom functions down into code that runs fast on the GPU, so that you can get on to doing something awesome."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
